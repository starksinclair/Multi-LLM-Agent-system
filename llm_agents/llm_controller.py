from enum import Enum
from typing import Optional

from pydantic import BaseModel
from .llm_provider import BaseLLM, LLMResponse
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class LLMTask(BaseModel):
    """
    Defines a task to be executed by an LLM within the medical query workflow.

    This Pydantic model encapsulates all necessary information for an LLM to
    perform a specific sub-task, including the prompt, system instructions,
    and flags indicating if external search is required.
    """
    task_id: str
    description: str
    prompt: str
    system_prompt: Optional[str] = None
    requires_search: bool = False
    requires_search_query_refinement: bool = False
    requires_search_result_refinement: bool = False


class LLMRole(Enum):
    """
        Enumerates the different roles an LLM can perform within the  medical query workflow.

        Each role is associated with a specific system prompt and set of responsibilities
        to guide the LLM's behavior and focus.
        """
    QUERY_REFINER = "query_refiner"
    RESEARCHER = "researcher"
    VALIDATOR = "validator"


def _get_system_prompts():
    """
    Provides a dictionary of system prompts for different LLM roles.

    These system prompts are designed to set the persona and specific instructions
    for each LLM role, guiding their behavior and output format.

    Returns:
        dict: A dictionary where keys are LLMRole enum members and values are
              corresponding system prompt strings.
    """
    return {
        LLMRole.QUERY_REFINER: """You are an expert medical search query optimizer. Your goal is to transform user questions into precise and effective search queries for medical research.
        Focus on using accurate medical terminology, adding relevant keywords, and formulating it for direct search result relevance (e.g., symptoms, treatments, drug info, disease mechanisms).
        The output should be only the refined query string, with no additional text or explanation. Do not include any conversational phrases or disclaimers.
        """,
        LLMRole.RESEARCHER: """You are a medical research agent. Your role is to:
        1. Analyze medical questions and identify key search terms
        2. Review search results and extract relevant medical information
        3. Focus on evidence-based information from reputable sources
        4. Always mention that medical information should be verified with healthcare professionals
        5. Be precise and factual in your analysis""",

        LLMRole.VALIDATOR: """You are a medical validation agent. Your role is to:
        1. Review final medical responses for accuracy and safety
        2. Ensure appropriate disclaimers are included
        3. Check that responses don't provide specific medical advice
        4. Validate that information is presented responsibly
        5. Flag any potentially harmful or misleading content.
        """,
    }


class MedicalLLMController:
    """
    Orchestrates the execution of LLM tasks for specific medical query roles.

    This controller class manages the interaction with an LLM instance to fulfill
    defined tasks. It applies role-specific system prompts and integrates
    external search context into the LLM's prompt when provided.
    """
    def __init__(self, role: LLMRole, llm: BaseLLM):
        self.role = role
        self.llm = llm
        self.system_prompts = _get_system_prompts()

    async def execute_task(self, task: LLMTask, search_context: Optional[str] = None) -> LLMResponse:
        """
        Executes a given LLM task, incorporating search context if provided.

        This asynchronous method prepares the full prompt for the LLM by combining
        the task's prompt with the search results. It then sends this
        to the configured LLM and returns the generated response.

        Args:
            task (LLMTask): The task to execute, containing the core prompt and flags.
            search_context (Optional[str]): Optional search results context to include in the prompt.

        Returns:
            LLMResponse: The response generated by the LLM, encapsulated with content,
                         provider, and model information.
        """
        search_info = ""
        full_prompt = task.prompt
        if search_context:
            search_info = f"\n\nSearch Results Context:\n{search_context}"
        full_prompt += search_info

        system_prompt = task.system_prompt or self.system_prompts.get(self.role, "")
        response = self.llm.generate_response(full_prompt, system_prompt)
        logger.info(f"Agent {self.role.value} ({self.llm.get_provider().value}) completed task: {task.task_id}")

        # Raise an exception if the response contains an error pattern
        if (
                isinstance(response.content, str)
                and ("error" in response.content.lower() or "503" in response.content)
        ):
            raise RuntimeError(f"LLM error: {response.content}")

        return response
